# 3.4 Arkin noncombatants
## Lethal autonomous systems and the plight of the non-combatant

## RONALD ARKIN <-- daar is je naam gerlof

RMA: revolution in military affairs, fundamental changes in the way war is waged.
Continued advances in autonomy might (if done correctly) result ina reduction in
atrocities, such as reducing civilian casualties and property damage. Restricted,
careful and graded instroduction into the battlefield must be standard policy -- 
being consistend with existing International Humanitarian Law (IHL).

Possible benefits of intelligent machines:
* a reduction in friendly casualties;
* force multiplication;
* expanding the battlespace;
* extending the warfighter's reach
* the ability to respond faster given the pressure of an ever increated battlefield
  tempo;
* greater precision due to persistent stare (constant video surveillance that enables
  more time for decision making and more eyes on target).

Therefore it is arguably that the development and deployment of lethal authonomous
systems are inevitable from a military efficiency and economic standpoint, unless 
limited by IHL.

It must be noted that past and present trends in human behavior in the battlefield
regarding adhering to legal and ethical requirements are questionable at best, despite
the introduction of HIL over the last 150 years.

Potential explanations for the persistence of war crimes include:
* high friendly losses leading to a tendency to seek revenge;
* high turnover in the chain of command leading to weakened leadership;
* dehumanization of the enemy through the use of derogatory names and epithets;
* poorly trained or inexperienced troops;
* no clearly defined enemy;
* unclear orders where intent of the order may be interpreted incorrectly as unlawful;
* youth and immaturity of troops;
* externel pressure, e.g. for a need to produce a high body count of the enemy;
* pleasure from power of killing or an overwhelming sense of frustration.

Autonomous systems may help address some of these issues. When suitably deployed, they
may assist with the plight of the innocent noncombatant caught in the battlefield. If, 
however, used without suitable precations, it could potentially exacerbate the already 
existing violations by human soldiers.

Expecting strict adherence to the Laws of War (LOW) seems unreasonable and unattainable
by a significant number of soldiers (modern warfare creates conditions for which no human
being was ever designed to function).

The dangers of abuse of unmanned robotic systems in war are well documented; they occur
even when a human operator is directly in charge.

The question then arises if and how these new robotic systems can conform as well as or 
better than human soldiers with respect to adherence to the existing IHL. If achievable,
this would result in a reduction in collateral damage (noncombatant casualties and damage
to civilian property). This therefore could result in a moral requirement necessitating the
use of these systems.

As robots are already faster, stronger and in certain cases smarter than humans, is it really
that difficult to believe they will be able to ultimately treat us more humanely in the
battlefield than we do eachother (given the persistent existence of war crimes).

## Why technology can lead to a reduction in casualties on the battlefield

* The ability to act conservatively, i.e., they do not need to protect themselves in cases
of low certainty of target identification.
* The eventual development and use of a broad range of robotic sensors better equipped for
battlefield observations than humans currently possess
* Unmanned robotic systems can be designed without emotions that cloud their judgement or 
result in anger and frustration with ongoing battlefield events.
* Avoidance of the human psychological problem of `scenario fulfillment' is possible. This
phenomenon leads to a distortion or neglect of contradictory information in stressful
situations, where humans use new incoming information in ways that only fit their
pre-existing belief patterns.
* Intelligent electronic systems can integrate more information from more sources far faster
before responding with lethal force than a human possibly could in real-time.
* When working in a team of combined human soldiers and autonomous systems as an organic asset,
they have the potential capability of independently and objectively monitoring ethical behavior
in the battlefield by all parties, providing evidence and reporting infractions that might be
observed. This presence alone might possibly lead to a reduction in human ethical infractions.

## Addressing some of the counter-arguments

Counterexamples include:
* the challenge of establishing responsibility for war crimes involving autonomous weaponry;
* the potential lowering of the threshold for entry into war;
* the military's possible reluctance of giving robots the right to refuse an order;
* proliferation;
* the effects on squad cohesion;
* the winning of hearts and minds;
* cybersecurity;
* mission creep.

If the baseline of criteria becomes outperforming humans in the battlefield with respect to 
adherence to IHL (without mission performance erosion), Ronald Arkin considers this to be 
ultimately attainable, especially under situational conditions where bounded morality (narrow,
highly situation-specific conditions) applies, but not soon and not easily.

The full moral faculties of humans need not be reproduced to attain to this standard. There are
profound technological challenges to be resolved, such as effective *in situ* target discrimination
and recognition of the status of those otherwise *hors de combat*, among many others. But if a 
warfighting robot can eventually exceed human performance with respect to IHL adherence, then that
equates to a saving of noncombatant lives and thus is a humanitarian effort. Indeed if this is
achievable, there may even exist a moral imperative for its use due to a resulting reduction in
collaterral damage, similar to the moral impoerative Human Rights WAtch has stated with respect
to precision guided munitions when used in urban settings.

## A plea for the noncombatant
It is crucially important that we not rush headlong into the design, development, and deployment
of these systems without thoroughly examining their consequences on all parties: friendly
forces, enemy combatants, civilians, and society in general. This can only be done through
reasoned discussion of the issues associated with this new technology.

The advent of these systems, if done properly, could possibly yield a greater adherence to the laws
of war by robotic systems than from using soldiers of flesh and blood alone.

## The way forward?
It clearly appears that the use of lethality by autonomous systems is inevitable, perhaps unless
outlawed by international law â€“ but even then enforcement seems challenging. But as stated
earlier, these systems already exist.

Under current IHL, these systems cannot be developed or used until they can demonstrate the
capability of adequate distinction, proportionality, and shown that they do not produce
unnecessary suffering, and must only be used given military necessity. Outside those bounds
any individuals responsible should be held accountable for violations of International
Humanitarian Law, whether they are scientists, industrialists, policymakers, commanders, or
soldiers. As these systems do not possess moral agency, the question of responsibility becomes
equated to other classes of weapon systems, and a human must always ultimately bear responsible
for their use.

Until it can be shown that the existing IHL is inadequate to cover this RMA, only then should
such action be taken to restructure or expand the law.

What must be stated is that a careful examination of the use of these systems must be
undertaken now to guide their development and deployment, which many of us believe is
inevitable given the ever increasing tempo of the battlefield as a result of ongoing
technological advances. It is unacceptable to be "one war behind" in the formulation of law
and policy regarding this revolution in military affairs that is already well underway. The
status quo with respect to human battlefield atrocities is unacceptable and emerging
technology in its manifold forms must be used to ameliorate the plight of the noncombatant.

