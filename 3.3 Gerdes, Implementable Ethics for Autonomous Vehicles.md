#Implementable Ethics for Autonomous Vehicles
J. Christian Gerdes, Sarah M. Thornton

## Introduction
Programmers have the ability to craft the response to different driving scenarios.
Despite it is argued to be impossible for AI to exhibit true moral behavior, society expects automated vehicles to do so. This fact also influences the social acceptance.

Can ethical frameworks and rules derived for human behavior be implemented as control algorithms in automated vehicles? -> Mapping turns out to be very well doable.

Very direct analogies between the frameworks of *consequentialism* and *deontological ethics* and cost functions combined with constraints can be drawn.

## Control Systems and Optimal Control
A **control system** aims to choose a set of control inputs that will achieve the desired goals. The resulting control laws consist of:

* existing knowledge of the goals
* a model of the system
* feedback control (correcting errors by comparing measurements of the environment with actual movement)

**Optiomal control** is a means to produce control laws for different goals and types of systems:

A cost function expresses the goal of the system and should thus be maximized or minimized
The cost function can be extended with other (smaller) goals. A weight per cost is added to distinguish between important goals and lesser important goals. These weights are very influential on the behavior of the system with even the smallest change and thus provide a good means to adjust the system.

The computational load such cost functions cause are not much of an issue anymore, since computational power increased significantly and efficient algorithms to solve optimization problems have been developed.

## Cost Functions and Consequentialism
**preference utilitarianism**: Aims to choose the set of options that provides the greatest benefit for the most actors.

**Consequentialism**: The consequences of one's conduct are the ultimate basis for any judgment about the rightness or wrongness of that conduct.

**Virtue ethics** for automated vehicles, proposed by Lin, can emulate professional behavior, for example that of a chauffeur trying to comfort his passengers.

Preference utilitarianism is very well suitable for cost functions. Thus, _this ethical framework is able to be mapped to mathematical values_.

problems:

* Massive amount of environmental data needed
* Ability to predict effects of collisions to determine the least harmful
* Self-sacrificing or protecting for example pedestrians?
* Object recognition is not 100% accurate and thus vital information might be missed


## Constraints and Deontological Ethics
*stom weetje: Blaise Pascal’s argument that belief in God’s existence is rational since the penalties for failing to believe and being incorrect are so great*

**Deontological ethics** judges the morality of an action based on the action's adherence to a rule or rules. (Action is more important than the consequences of taking it).

**Constraints** aim to enforce behavior no matter how high the cost, e.g. avoiding collisions.

**Soft constraints (slack variables)** are constraints that can be overruled by more important constraints, replacing the soft constraint with a high cost.

**Three Laws of Robotics** by _Isaac Asimov_:

1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.
2. A robot must obey the orders given to it by human beings, except where such orders would conflict with the First Law.
3. A robot must protect its own existence, as long as such protection does not conflict with the First or Second Law.

**Three Adjusted Laws of Robotics** by _Gerdes_:

1. An automated vehicle should not collide with a pedestrian or cyclist.
2. An automated vehicle should not collide with another vehicle, except where avoiding
such a collision would conflict with the First Law.
3. An automated vehicle should not collide with any other object in the environment,
except where avoiding such a collision would conflict with the First or Second Law.

With constraints, one shifts from the _consequentialist's_ approach to a _deontological_ approach. Mathematically, this can be denoted by placing constraints on the cost function (mainly limits).

To prioritize constraints over another, _soft constraints_ (_slack variables_) can be used. This way, no infeasible situations can occur.

Appropriate hierarchy of rules for a deontological basis for ethical actions: the _Three Laws of Robotics_ cause conflicts in autonous driving. Adjusting these, replacing "harm and injury" with the more general "collisions" and prioritizing human life and the most vulnerable road users yields:

1. An automated vehicle should not collide with a pedestrian or cyclist.
2. An automated vehicle should not collide with another vehicle, except where avoiding
such a collision would conflict with the First Law.
3. An automated vehicle should not collide with any other object in the environment,
except where avoiding such a collision would conflict with the First or Second Law.

## Traffic Laws - Constraint or Cost?
Traffic laws seem deontological, but in practice many treat them as guidelines rather than rules. Therefore they are better suited for the consequentialist approach.

If automated vehicles are to co-exist with human drivers in traffic and behave similarly, a deontological approach to collision avoidance and a consequentialist approach to the rules of the road may achieve this.

## Simple Implementation of Ethical Rules

**Erlien et al** proposed an approach for collision avoidance and vehicle automation.

_one large example, not included here_

## Human Override and the "Big Red Button"
According to the Three Laws of Robotics, human commands (Second Law) cannot override the need for protection of human life (First Law). The presence of a "panic button" that returns control to humans conflicts this fact.
Is it ethical for the machine to return control to the human after the "panic button" is pressed? This question needs to be decided on, but it seems likely that when machines have gathered enough trust they will have the final word.
